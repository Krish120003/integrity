{
  "generate_answer": {
    "lm": null,
    "traces": [],
    "train": [],
    "demos": [
      {
        "augmented": true,
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "FreshVision determines when fresh produce in your fridge is ripe, using machine learning. When cameras in the fridge detect a food is ripe, the user is sent an SMS message along with some recipes.Our contact page \n \n \n \n \n \n   \n \n Our about us page\n\nInspiration \n How many times have you seen that your produce (fruits\/veggies) has gone rotten or has been aimlessly sitting around in your fridge? Every year, about 17% of fresh produce goes to waste for this reason; but it doesn\u2019t have to be this way. FreshVision aims to solve this problem and to make cooking with healthy ingredients easier, all to ensure we minimize food waste, keep people healthy, and make peoples\u2019 lives easier. We also aim to help achieve SDG 12: Responsible Consumption and Production in this way. \n What it does \n FreshVision solves this waste problem by making sure you know when your food is ripe and suggests recipes for you to use so that your food doesn\u2019t sit around and go to waste. By using antifreeze cameras installed in your fridge, photos of your produce will be taken every 3 hours and sent to a machine learning model and web app to determine if anything is ripe. Whenever the model notices that something is ripe, the web app sends an SMS text message telling the user. The web app also accesses a recipe database that will showcase recipes for the ripe food to the user. As mentioned earlier, this will encourage users to cook with their produce, minimize food waste, and encourage healthy eating. The web app also contains an About Us and Contact page, fit for users to learn more about us and our mission. \n *Due to hardware limitations, the prototype currently accepts image uploads rather than taking them from antifreeze cameras. \n ",
        "rationale": "Reasoning: Let's think step by step in order to ${produce the answer}. We need to compare the core functionalities, target audiences, and overall goals of both projects. \n\n* **Core Functionalities:** Project 1 focuses on AI-powered assistance for visually impaired individuals, using object identification, facial recognition, and interactive question answering. Project 2 focuses on using machine learning to detect ripe produce in a fridge and sending recipe suggestions. While both projects utilize AI, their specific applications and functionalities are distinct.\n* **Target Audiences:** Project 1 targets visually impaired individuals, aiming to improve their navigation and interaction with the world. Project 2 targets a broader audience, aiming to reduce food waste and promote healthy eating habits.\n* **Overall Goals:** Project 1 aims to enhance the independence and quality of life for visually impaired individuals. Project 2 aims to address the issue of food waste and encourage healthy eating. While both projects have positive social impacts, their specific goals and approaches are different.",
        "answer": "No"
      },
      {
        "augmented": true,
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "N\/AN\/A \n Inspiration \n What it does \n ",
        "rationale": "Project 1: Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone. CAD Prototype CAD Prototype A close up view of the saight mount on a white cane Inspiration One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. Looking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently. What it does Object Identification: Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. Facial Recognition: It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. Interactive Question Answering: Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. Voice Commands: Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra.\n\nProject 2: N\/AN\/A Inspiration What it does\n\nReasoning: Let's think step by step in order to ${produce the answer}. We need to compare the two projects to see if they share enough similarities to warrant a plagiarism investigation. Project 1 provides a detailed description of an AI-based assistance for visually impaired individuals, including its features, inspiration, and purpose. Project 2, however, is completely empty, lacking any information. Without any details about Project 2, we cannot determine if there are any similarities or potential plagiarism.",
        "answer": "No"
      },
      {
        "augmented": true,
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "An innovative machine learning model that empowers the visually impaired to perceive their surroundings using auditory cues.Source Image 1: Object Detection \n \n \n \n \n \n   \n \n The labels for the Object Detection are accurate, with the top ones being a pair of pants and shoe. \n \n \n \n \n \n   \n \n Source Image 2: Handwritten Sticky Note \n \n \n \n \n \n   \n \n The LLM accurately detected the text, including the punctuation and case. \n \n \n \n \n \n   \n \n Face Classification based on users saved on the database.\nInspiration \n During our research stage, we found it intriguing that 5.4% of Canadians aged 15 years and older report having a visual disability. It is a sad, yet true, fact that highlights how much of the population is struggling with the disability. Our inspiration stemmed from the thought of incorporating AI and text-to-speech technology to make aspects of life more accessible to the visually disabled. We brainstormed several ideas to highlight how we can give blind people a way to see through their hearing.  \n What it does \n The dragonfl.ai headset is made up of three major features: facial recognition, object identification, and voice commands. The features are tied together with text-to-speech to fully bring sight through sound.  \n ",
        "rationale": "Reasoning: Let's think step by step in order to ${produce the answer}. We need to compare the key elements of both projects to determine if they are too similar. Both projects focus on using AI to help visually impaired individuals navigate their surroundings. They both utilize object identification, facial recognition, and voice commands. However, Project 1 focuses on a physical device (a smartphone mount attached to a white cane) while Project 2 focuses on a headset. The specific technologies used and the overall approach to the problem are similar, but the implementation and the final product are distinct.",
        "answer": "Yes"
      },
      {
        "augmented": true,
        "project_1": "WealthNest is a personal finance manager for university students. It alerts them of what they should find to be most important while using ML to advise users of possible financial plans. Inspiration One of our friends Kenny was losing all his money just spending it on food and nights out, so we felt inclined to create a product for university students to manage their money well. What it does Is a simple financial managing app including the following: Expense tracking Budgeting + goal setting Bill reminders Saving + investment tools Student discounts Financial ed. resources Scholarship + grant info. Loan repayment planner Expense sharing + splitting",
        "project_2": "Did you know that only 9% of the plastic ever produced has been recycled? Let's face it; Everyone knows recycling is important. We were all taught at a young age about how recycling reduces our carbon footprint, produces less waste, and is more sustainable for the planet.  So why is it that no one does it? Well, recycling is not always that simple. Firstly, it can be confusing to figure out what types of trash can be recycled. We have all stood in front of a trash can in confusion, wondering if our candy wrappers are recyclable or not. Secondly, recycling cans and trash cans are often placed apart, leading to laziness and unwillingness to track down the nearest recycling bin. Lastly, it is easy to forget to recycle at times, the thought completely leaving our head.   Inspired by this dilemma, we wanted to create a product that took all of the tedious decision-making out of your hands. Wouldn't it be nice to be able to mindlessly throw your trash in one place, and let AI handle the sorting for you? How does IntelliBin 2.0 work? IntelliBin 2.0 uses a servo-motor-controlled arm to sort trash between two recycling bins. First, our webcam detects motion using OpenCV when the user places a piece of trash onto our system platform. Then, a camera is taken of the object, and the type of trash is identified using Google Cloud's Vision API. Next, depending on the type of trash detected, our Arduino activates our servo-motor using C++ code to turn our robot arm left or right, sorting the trash into one of two trashcans.  Users can register for an account on our hosted website at  https:\/\/Intellibin.Tech\/ . Once logged in, they can generate a custom QR code on our website. Users can connect their IntelliBin with their online account by scanning this QR code on the IntelliBin webcam. Once connected, each time the user recycles a piece of trash, it is recorded and added to their recycling history. On our website, users can view their daily and total recycling statistics, which are stored using Google's Firestore and updated live. Coins are earned by recycling more objects, which can then be used to buy custom avatars. An updated leaderboard is kept to motivate some friendly competition between all users and incentivize recycling.",
        "rationale": "Reasoning: Let's think step by step in order to ${produce the answer}. We need to compare the two projects and see if they share any significant similarities in terms of their core functionality, target audience, or the technology used. \n\nProject 1 focuses on personal finance management for university students, using ML for financial advice. It offers features like expense tracking, budgeting, bill reminders, and student discounts. \n\nProject 2 focuses on automated trash sorting using AI and robotics. It uses a webcam, Google Cloud Vision API, Arduino, and a servo-motor to identify and sort trash. It also includes a website for user accounts, recycling statistics, and gamification elements.\n\nThe two projects have very different goals, target audiences, and technical implementations. Project 1 is a software application focused on personal finance, while Project 2 is a hardware-based system for automated recycling.",
        "answer": "No"
      },
      {
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "An AI-based personal therapist at your fingertips.Otto, your personalised AI therapist available at anytime, through SMS. \n \n \n \n \n \n   \n \n Otto uses an Airtable Database to store chat logs. These logs are used to derive analytical insights into user behaviour and chat summaries. \n \n \n \n \n \n   \n \n Upon invoking the \/e command, the user will get an email summary of past journal entries. Can be used to generalize user behaviour trends. \n \n \n \n \n \n   \n \n The \/j command makes journaling, easier than ever. With Otto, write reflective entries and receive helpful follow up questions.\n\nInspiration \n When Hetav was in grade 7, Hetav\u2019s best friend lost their grandmother due the covid pandemic. He was grieving greatly and he needed someone to talk to. Due to cultural influences and societal stigma surronding mental care support, Hetav\u2019s friend did not opt for a therapist. Even if he wanted to, these services were in shortage and had long waitlists. \n What it does \n Otto is a personalised therapist that is available through SMS anytime. He is approachable, empathetic and shares authentic, heart-felt conversations with those who need it the most. Otto breaks the stigma around mental care support by seamlessly integrating into youth culture through texting, a common comfort zone for students.  \n He has many features such as authentic conversation; journaling, a popular mental health briefing strategy; a summary feature, offering the user an opportunity to step back and reflect on all the past conversations; an analytical tool, providing a way for professional therapists, doctors and parents to gain insights into user behaviour; and an emaling feature to email journal summaries. \n Target Audience : Students\/Youth (However, all ages are able to use Otto) \n ",
        "should_investigate": "no"
      },
      {
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "Hawkeye gives independence to the visually impaired. Users can Q&A their surroundings, recognize faces using AI, and screenlessly search the internet all within less than one second.\n\nInspiration \n Our team focuses on real-world problems. One of our own classmates is blind, and we've witnessed firsthand the difficulties he encounters during lectures, particularly when it comes to accessing the information presented on the board. \n It's a powerful reminder that innovation isn't just about creating flashy technology; it's about making a tangible impact on people's lives. \"Hawkeye\" isn't a theoretical concept; it's a practical solution born from a genuine need. \n What it does \n \"Hawkeye\" utilizes Adhawk MindLink to provide essential visual information to the blind and visually impaired. Our application offers a wide range of functions: \n \n Text Recognition : \"Hawkeye\" can read aloud whiteboard text, screens, and all text that our users would not otherwise see. \n Object Identification : The application identifies text and objects in the user's environment, providing information about their size, shape, and position. \n Answering Questions  Hawkeye takes the place of Google for the visually impaired, using pure voice commands to search \n \n ",
        "should_investigate": "yes"
      },
      {
        "project_1": "Never Worry About Sorting Your Trash Again Start Smart Sorting With AI; the Green, Clean, and Smart Way! Have you ever faced a trashcan with a seemingly endless number of bins, each one marked with a different type of recycling? Have you ever held some trash in your hand, desperately wondering if it can be recycled? Have you ever been forced to sort your trash in your house, the different bins taking up space and being an eyesore? Inspired by this dilemma, we wanted to create a product that took all of the tedious decision-making out of your hands. Wouldn't it be nice to be able to mindlessly throw your trash in one place, and let AI handle the sorting for you?  What it does IntelliBin is an AI trashcan that handles your trash sorting for you! Simply place your trash onto our machine, and watch it be sorted automatically by IntelliBin's servo arm! Furthermore, you can track your stats and learn more about recycling on our React.js website.  ",
        "project_2": "Did you know that only 9% of the plastic ever produced has been recycled? Let's face it; Everyone knows recycling is important. We were all taught at a young age about how recycling reduces our carbon footprint, produces less waste, and is more sustainable for the planet.  So why is it that no one does it? Well, recycling is not always that simple. Firstly, it can be confusing to figure out what types of trash can be recycled. We have all stood in front of a trash can in confusion, wondering if our candy wrappers are recyclable or not. Secondly, recycling cans and trash cans are often placed apart, leading to laziness and unwillingness to track down the nearest recycling bin. Lastly, it is easy to forget to recycle at times, the thought completely leaving our head.   Inspired by this dilemma, we wanted to create a product that took all of the tedious decision-making out of your hands. Wouldn't it be nice to be able to mindlessly throw your trash in one place, and let AI handle the sorting for you? How does IntelliBin 2.0 work? IntelliBin 2.0 uses a servo-motor-controlled arm to sort trash between two recycling bins. First, our webcam detects motion using OpenCV when the user places a piece of trash onto our system platform. Then, a camera is taken of the object, and the type of trash is identified using Google Cloud's Vision API. Next, depending on the type of trash detected, our Arduino activates our servo-motor using C++ code to turn our robot arm left or right, sorting the trash into one of two trashcans.  Users can register for an account on our hosted website at  https:\/\/Intellibin.Tech\/ . Once logged in, they can generate a custom QR code on our website. Users can connect their IntelliBin with their online account by scanning this QR code on the IntelliBin webcam. Once connected, each time the user recycles a piece of trash, it is recorded and added to their recycling history. On our website, users can view their daily and total recycling statistics, which are stored using Google's Firestore and updated live. Coins are earned by recycling more objects, which can then be used to buy custom avatars. An updated leaderboard is kept to motivate some friendly competition between all users and incentivize recycling.",
        "should_investigate": "yes"
      },
      {
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "MediScan is a free and accessible website to detect pneumonia based on machine learning using collected chest scans.Inspiration \n We initially thought of this idea because of the statistics for pneumonia that we noticed. It was eye-opening to see how many deaths were caused by undiagnosed pneumonia.  \n What it does \n MediScan uses machine learning to detect pneumonia scans based on x-ray scans collected.  \n ",
        "should_investigate": "no"
      },
      {
        "project_1": "Saight is an AI-based assistance with a smartphone mount, which can be attached to any white cane. This can help the visually-impaired navigate the world. A demonstration of the mount with a smartphone.  \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n CAD Prototype \n \n \n \n \n \n   \n \n A close up view of the saight mount on a white cane\n\nInspiration \n One of our teammate\u2019s grandfathers suffers from diabetic retinopathy, which causes severe vision loss. \nLooking on a broader scale, over 2.2 billion people suffer from near or distant vision impairment worldwide. After examining the issue closer, it can be confirmed that the issue disproportionately affects people over the age of 50 years old. We wanted to create a solution that would help them navigate the complex world independently.  \n What it does \n Object Identification: \n Utilizes advanced computer vision to identify and describe objects in the user's surroundings, providing real-time audio feedback. \n Facial Recognition: \n It employs machine learning for facial recognition, enabling users to recognize and remember familiar faces, and fostering a deeper connection with their environment. \n Interactive Question Answering: \n Acts as an on-demand information resource, allowing users to ask questions and receive accurate answers, covering a wide range of topics. \n Voice Commands: \n Features a user-friendly voice command system accessible to all, facilitating seamless interaction with the AI assistant: Sierra. \n",
        "project_2": "There is plenty of data about what makes you, you, but it's just siloed in a bunch of apps. Friended aims to build you a personal profile out of that data and help you build meaningful connections.\n\nInspiration \n We were inspired to make this project after we went through the process of finding a hackathon team ourselves. Though there exists a Discord channel and Devpost's features to filter through participants, we felt that they were not enough to help people reliably create teams. We felt that there was a method with greater clarity that could be established to help team members come together all while keeping compatibility in mind. That's where the idea of friended. was born.  \n What it does \n There is plenty of data about what makes you, you \ud83d\ude0a. It\u2019s just siloed in a bunch of apps \ud83d\ude14. That data is useful because it can help you find you\u2019re next hackathon team, co-founder, friend, partner\u2026 \nfriended. brings your digital data into one place and finds people like you. It takes your interests, skills, and experiences from Devpost and LinkedIn and leverages OpenAI embeddings to allow for Supabase vector similarity search. This allows for use cases like helping hackathon organizers set up teams. Organizers can set up events for participants to meet and discover people participating in the hackathon with similar interests, skills, and work experiences. Ultimately, friended. helps you build meaningful connections through your pre-existing, public data. \n ",
        "should_investigate": "no"
      },
      {
        "project_1": "An ambient LED lighting system that enhances the experience for space travelers as the dystopian society of Earth forced them to travel to a new planet.Inspiration: To create an innovation that will help improve the mental health of people who are leaving Earth due to its horrible conditions so that civilians will not have negative impacts on their mental health. Ambient LED lighting will provide the opportunity to change ambiance feelings and moods. What it does: It allows the user to change through millions of colors to set the mood of the space shuttle to suit them.",
        "project_2": "WealthNest is a personal finance manager for university students. It alerts them of what they should find to be most important while using ML to advise users of possible financial plans. Inspiration One of our friends Kenny was losing all his money just spending it on food and nights out, so we felt inclined to create a product for university students to manage their money well. What it does Is a simple financial managing app including the following: Expense tracking Budgeting + goal setting Bill reminders Saving + investment tools Student discounts Financial ed. resources Scholarship + grant info. Loan repayment planner Expense sharing + splitting",
        "should_investigate": "no"
      }
    ],
    "signature_instructions": "Decide whether two projects are similar enough to investigate plagiarism.",
    "signature_prefix": "Answer:",
    "extended_signature_instructions": "Decide whether two projects are similar enough to investigate plagiarism.",
    "extended_signature_prefix": "Answer:"
  }
}